{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOdqsvG0Z+RC2I9JAeiZJ2C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alafiade/Knowledge-distillation-using-Cosine-runLoss-Minimization/blob/main/Knowledge_Distillation_using_Cosine_Loss_Minimization_run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTING DEPENDENCIES"
      ],
      "metadata": {
        "id": "n4G-k6g0myGJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6NK_-SAMvzP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else 'cpu'\n",
        "print (f'Using {device}device')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOKFcnkZOUK0",
        "outputId": "ea11772b-3af0-4a8e-e5b9-8b0f1ccd5ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cudadevice\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA LOADING AND PREPROCESSING"
      ],
      "metadata": {
        "id": "wlYMD9ram-v0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transforms_cifar = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.299,0.224,0.225])\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms_cifar)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms_cifar)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNX8ZmDWO1uo",
        "outputId": "3538d88b-3d06-4765-da60-d3d77117b133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:05<00:00, 33.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SETTING DATA LOADERS"
      ],
      "metadata": {
        "id": "Q9LcJUmTnJhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "JvC3LTwXP2El"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINING MODEL"
      ],
      "metadata": {
        "id": "C7JiTbPbnWvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepNN(nn.Module):\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(DeepNN, self). __init__()\n",
        "    self.features = nn.Sequential(\n",
        "        nn.Conv2d(3,128,kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(128,64,kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Conv2d(64,32,kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(2048,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.1),\n",
        "        nn.Linear(512,num_classes)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    x = self.features(x)\n",
        "    x = torch.flatten(x,1)\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "#Lightweight neural network class to be used as student:\n",
        "class LightNN(nn.Module):\n",
        "  def __init__(self,num_classes=10):\n",
        "    super(LightNN, self). __init__()\n",
        "    self.features = nn.Sequential(\n",
        "        nn.Conv2d(3,16, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Conv2d(16,16, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(1024,256),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.1),\n",
        "        nn.Linear(256,num_classes)\n",
        "\n",
        "\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.features(x)\n",
        "    x = torch.flatten(x,1)\n",
        "    x = self.classifier(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "Pz-TfegbQ-FR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, epochs, learning_rate, device):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "def test(model, test_loader, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "xhV6q0XDYzss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CROSS ENTROPY RUNS"
      ],
      "metadata": {
        "id": "ziylJOP2ZBZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "nn_deep = DeepNN(num_classes=10).to(device)\n",
        "train(nn_deep, train_loader, epochs=10, learning_rate=0.001, device=device)\n",
        "test_accuracy_deep = test(nn_deep, test_loader, device)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "nn_light = LightNN(num_classes=10).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE_2297zY_If",
        "outputId": "8085e6fc-5af2-4dc2-92e0-5172fde07ead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.3288499415683015\n",
            "Epoch 2/10, Loss: 0.878422740475296\n",
            "Epoch 3/10, Loss: 0.6890814704510867\n",
            "Epoch 4/10, Loss: 0.547064641552508\n",
            "Epoch 5/10, Loss: 0.42462955426681986\n",
            "Epoch 6/10, Loss: 0.31261353587250573\n",
            "Epoch 7/10, Loss: 0.22779948868410058\n",
            "Epoch 8/10, Loss: 0.16838190793190771\n",
            "Epoch 9/10, Loss: 0.1418863251862471\n",
            "Epoch 10/10, Loss: 0.12091316542852565\n",
            "Test Accuracy: 74.17%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d2l1mNa_IFrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "new_nn_light = LightNN(num_classes=10).to(device)"
      ],
      "metadata": {
        "id": "dtlhHHpmd1jC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing the first layer of the initial lightweight model and the new lightweight model"
      ],
      "metadata": {
        "id": "-yIyP8OpeF91"
      }
    },
    {
      "source": [
        "print('Norm of 1st layer of nn_light:', torch.norm(nn_light.features[0].weight).item()) # Corrected to nn_light\n",
        "print('Norm of 1st layer of new_nn_light:', torch.norm(new_nn_light.features[0].weight).item()) # Corrected to new_nn_light"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AadCjwcHfEUX",
        "outputId": "e4b30bf0-6a7e-41c5-90cb-82765dd6d5ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm of 1st layer of nn_light: 2.327361822128296\n",
            "Norm of 1st layer of new_nn_light: 2.327361822128296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params_deep = '{:,}'.format(sum(p.numel() for p in nn_deep.parameters()))\n",
        "total_params_light = '{:,}'.format(sum(p.numel()for p in nn_light.parameters()))\n",
        "print(f'Deep NN parameters: {total_params_deep}')\n",
        "print(f' LightNN parameters: {total_params_light}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kUmhbXKflkN",
        "outputId": "373781ce-f29a-4238-a42f-49dba1bd8497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deep NN parameters: 1,150,058\n",
            " LightNN parameters: 267,738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(nn_light, train_loader, epochs=10, learning_rate=0.001, device=device)\n",
        "test_accuracy_light_ce = test(nn_light,test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-OfseGngrJ3",
        "outputId": "e15a0787-37d7-481d-ea71-cdb2008c7fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.4754226991282704\n",
            "Epoch 2/10, Loss: 1.1681805099062907\n",
            "Epoch 3/10, Loss: 1.039349402003276\n",
            "Epoch 4/10, Loss: 0.9384047581106806\n",
            "Epoch 5/10, Loss: 0.8638731817455243\n",
            "Epoch 6/10, Loss: 0.7978585077368695\n",
            "Epoch 7/10, Loss: 0.7358091481963692\n",
            "Epoch 8/10, Loss: 0.6794487219637312\n",
            "Epoch 9/10, Loss: 0.626218048203022\n",
            "Epoch 10/10, Loss: 0.5802044873042485\n",
            "Test Accuracy: 70.54%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Test accuracy of DeepNN: {test_accuracy_deep:.2f}%')\n",
        "print(f'Test accuracy of LightNN: {test_accuracy_light_ce:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsIXSEGChpaR",
        "outputId": "a0c2c0c7-0014-4a78-e2f9-f05aa9e64f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy of DeepNN: 74.17%\n",
            "Test accuracy of LightNN: 70.54%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAVING MODEL"
      ],
      "metadata": {
        "id": "YP35pS22IL-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(nn_deep.state_dict(), 'deep_model.pth')\n",
        "torch.save(nn_light.state_dict(), 'light_model.pth')"
      ],
      "metadata": {
        "id": "9b8kPKbDzxsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODIFIED STUDENT AND TEACHER ARCHITECTURE"
      ],
      "metadata": {
        "id": "fB_BOP7yITT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModifiedDeepNNCosine(nn.Module):\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(ModifiedDeepNNCosine, self).__init__()\n",
        "    self.features = nn.Sequential(\n",
        "        nn.Conv2d(3,128, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(128,64, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Conv2d(64,64, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(64,32, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,  stride=2),\n",
        "\n",
        "\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(2048,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.1),\n",
        "        nn.Linear(512, num_classes)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.features(x)\n",
        "    flattened_conv_output = torch.flatten(x,1)\n",
        "    x = self.classifier(flattened_conv_output)\n",
        "    flattened_conv_output_after_pooling = torch.nn.functional.avg_pool1d(flattened_conv_output,2)\n",
        "    return x, flattened_conv_output_after_pooling\n",
        "\n",
        "\n",
        "class ModifiedLightNNCosine(nn.Module):\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(ModifiedLightNNCosine, self). __init__()\n",
        "    self.features = nn.Sequential(\n",
        "        nn.Conv2d(3,16, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Conv2d(16,16, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(1024,256),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.1),\n",
        "        nn.Linear(256, num_classes)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    x = self.features(x)\n",
        "    flattened_conv_output = torch.flatten(x,1)\n",
        "    x = self.classifier(flattened_conv_output)\n",
        "    return x, flattened_conv_output"
      ],
      "metadata": {
        "id": "5I5lbG0x0Px8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modified_nn_deep = ModifiedDeepNNCosine(num_classes=10).to(device)\n",
        "original_state_dict = nn_deep.state_dict()\n",
        "modified_state_dict = modified_nn_deep.state_dict()\n",
        "\n",
        "for name, param in original_state_dict.items():\n",
        "  if name in modified_state_dict and param.shape == modified_state_dict[name].shape:\n",
        "    modified_state_dict[name].copy_(param)\n",
        "\n",
        "modified_nn_deep.load_state_dict(modified_state_dict, strict=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wvxWkQu_E-9",
        "outputId": "a73b42f8-e16f-4675-e91c-211587eec113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the norm of the first layer for both modified and previous network\n",
        "print('Norm of 1st layer for deep_nn:', torch.norm(nn_deep.features[0].weight).item())\n",
        "print('Norm of 1st layer for modified_deep_nn:', torch.norm(modified_nn_deep.features[0].weight).item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t42Oh12yAXUl",
        "outputId": "a8ef0a13-aa38-40cc-a753-9b0a2a0a8af9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm of 1st layer for deep_nn: 7.891228199005127\n",
            "Norm of 1st layer for modified_deep_nn: 7.891228199005127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the Modified Light weight network with the same seed as our previous lightweight instances\n",
        "torch.manual_seed(42)\n",
        "modified_nn_light = ModifiedLightNNCosine(num_classes=10).to(device)\n",
        "print('Norm of 1st layer:', torch.norm(modified_nn_light.features[0].weight).item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR27pgmWBsKf",
        "outputId": "302e7b28-d9f2-4f87-df22-65a7cc08782d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm of 1st layer: 2.327361822128296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREPARING MODEL FOR DISTILLATION"
      ],
      "metadata": {
        "id": "XcX0wUx7Bdxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input = torch.randn(128,3,32,32).to(device)\n",
        "logits, hidden_representation = modified_nn_light(sample_input)\n",
        "\n",
        "print('Student logits shape:', logits.shape)\n",
        "print('Student hidden representation shape:', hidden_representation.shape)\n",
        "\n",
        "logits, hidden_representation = modified_nn_deep(sample_input)\n",
        "\n",
        "print('Teacher logits shape:', logits.shape)\n",
        "print('Teacher hidden representation shape:', hidden_representation.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3L7jeNNBsEM",
        "outputId": "1d2bbbe9-6f53-4061-d550-29d995e8476b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student logits shape: torch.Size([128, 10])\n",
            "Student hidden representation shape: torch.Size([128, 1024])\n",
            "Teacher logits shape: torch.Size([128, 10])\n",
            "Teacher hidden representation shape: torch.Size([128, 1024])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPLEMENTING KNOWLEDGE DISTILLATION TRAININGG PROCESS USING COSINE EMBEDDING LOSS"
      ],
      "metadata": {
        "id": "maXyiHEtCQ9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_cosine_loss(teacher, student, train_loader, epochs, learning_rate, hidden_rep_loss_weight, ce_loss_weight,device):\n",
        "  ce_loss = nn.CrossEntropyLoss()\n",
        "  cosine_loss = nn.CosineEmbeddingLoss()\n",
        "  optimizer = optim.Adam(student.parameters(), lr=learning_rate)\n",
        "\n",
        "  # Ensure both teacher and student models are on the correct device\n",
        "  teacher.to(device)\n",
        "  student.to(device)\n",
        "  teacher.eval()\n",
        "  student.train()\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "      # Ensure inputs and labels are on the correct device\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      # Forward pass with the teacher model and keep only hidden representation\n",
        "      with torch.no_grad():\n",
        "        _, teacher_hidden_representation = teacher(inputs)\n",
        "\n",
        "      student_logits, student_hidden_representation = student(inputs)\n",
        "\n",
        "      hidden_rep_loss = cosine_loss(student_hidden_representation, teacher_hidden_representation, target=torch.ones(inputs.size(0)).to(device))\n",
        "\n",
        "      label_loss = ce_loss(student_logits, labels)\n",
        "\n",
        "      loss = hidden_rep_loss_weight * hidden_rep_loss + ce_loss_weight * label_loss\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Loss:{running_loss/len(train_loader)}')"
      ],
      "metadata": {
        "id": "wqKqrTp7KCh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVALUATION ON THE TEST DATASET"
      ],
      "metadata": {
        "id": "Rjna2wwkCz00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_multiple_outputs(model, test_loader, device):\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "      # The model returns two values, so we unpack them into outputs and _\n",
        "      outputs, _ = model(inputs)  # Changed this line\n",
        "      _, predicted = torch.max(outputs.data,1)\n",
        "\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  accuracy = 100 * correct / total\n",
        "  print(f'Test Accuracy: {accuracy:.2f}%')\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "cdO-JXGOK32n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_cosine_loss(teacher= modified_nn_deep, student=modified_nn_light, train_loader=train_loader, epochs=10, learning_rate=0.001, hidden_rep_loss_weight=0.25, ce_loss_weight=0.75, device=device  )\n",
        "test_accuracy_light_ce_and_cosine_loss = test_multiple_outputs(modified_nn_light,test_loader,device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxZVfrRLIPms",
        "outputId": "83a4054a-1841-4559-f1e3-304a36c24538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss:0.6063390386378978\n",
            "Epoch 2/10, Loss:0.5788718739433971\n",
            "Epoch 3/10, Loss:0.557668267156157\n",
            "Epoch 4/10, Loss:0.532042542915515\n",
            "Epoch 5/10, Loss:0.5103208540040819\n",
            "Epoch 6/10, Loss:0.49039658492483446\n",
            "Epoch 7/10, Loss:0.4699215755590697\n",
            "Epoch 8/10, Loss:0.4498132763768706\n",
            "Epoch 9/10, Loss:0.4319571669754165\n",
            "Epoch 10/10, Loss:0.416853809410044\n",
            "Test Accuracy: 71.15%\n"
          ]
        }
      ]
    }
  ]
}